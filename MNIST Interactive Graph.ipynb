{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Create a neural network graph and setup training steps for \n",
    "# a neural network to use and learn from the MNIST dataset.\n",
    "\n",
    "# Import modules necessary for MNIST Experiment\n",
    "import tensorflow as tf\n",
    "\n",
    "#Import example\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#Setup data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784]) #Input values (N images by 784 pixels per image)\n",
    "W = tf.Variable(tf.zeros([784, 10]))        #Weight values for input (784 pixels by 10 possible digits)\n",
    "b = tf.Variable(tf.zeros([10]))             #Bias values for each digit\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)      #Output vector, Softmax(Wx + b)\n",
    "\n",
    "# Define loss placeholder\n",
    "y_ = tf.placeholder(tf.float32, [None, 10]) #How far is result from actual\n",
    "# Create cross_entropy function based on loss and actual\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "# Instruct TensorFlow to attempt to minimize the cross_entropy using the Gradient Descent \n",
    "# Optimizer with a learning value of 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing the required packages\n",
    "import numpy as np\n",
    "from sklearn import manifold\n",
    "\n",
    "# Initialize and save variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()     #Start new Session\n",
    "sess.run(init)          #Initialize variables\n",
    "\n",
    "#Number of steps to run\n",
    "num_steps = 1000\n",
    "\n",
    "#Number of samples for data collection\n",
    "n_samples = 100\n",
    "#Number of steps between sample collection\n",
    "sample_gap = 10\n",
    "#Define a way to save parameters for graph\n",
    "graphs = np.zeros(shape=(num_steps // sample_gap + 1, #One dimension for each step in time\n",
    "                         n_samples,                #One dimension each sample taken\n",
    "                         2))                       #One dimension for vector data (2 from a 2d graph)\n",
    "#Setup function for computing t-SNE for graphs\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    \n",
    "# Run training steps Num Steps times\n",
    "for n in range(num_steps):\n",
    "    #Before training the neural network, check if this is a sample step\n",
    "    #Done before so it can include before training\n",
    "    if n % sample_gap == 0:\n",
    "        #Load n samples from the training dataset\n",
    "        #Batch_x are the input images as a flattened 784 pixel vector\n",
    "        #Batch_y is a vector of what number the image represents\n",
    "        batch_x, batch_y = mnist.train.next_batch(n_samples)\n",
    "        X = sess.run(y, feed_dict={x:batch_x})\n",
    "        \n",
    "        # (This is slow but precomputed) Computing t-SNE projection\n",
    "        tsne_vector = tsne.fit_transform(X)\n",
    "        graphs[n // sample_gap] = tsne_vector;\n",
    "                  \n",
    "    #Get a batch of 100 images\n",
    "    #Batch_x are the input images as a flattened 784 pixel vector\n",
    "    #Batch_y is a vector of what number the image represents\n",
    "    batch_x, batch_y = mnist.train.next_batch(100)\n",
    "    \n",
    "    #Run the session with the given data (Do one training step)\n",
    "    sess.run(train_step, feed_dict={x: batch_x, y_: batch_y})\n",
    "\n",
    "#Final sample colleciton after training is complete\n",
    "#Load n samples from the training dataset\n",
    "#Batch_x are the input images as a flattened 784 pixel vector\n",
    "#Batch_y is a vector of what number the image represents\n",
    "batch_x, batch_y = mnist.train.next_batch(n_samples)\n",
    "X = sess.run(y, feed_dict={x:batch_x})\n",
    "\n",
    "# (This is slow but precomputed) Computing t-SNE projection\n",
    "tsne_vector = tsne.fit_transform(X)\n",
    "graphs[len(graph) - 1] = tsne_vector;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ],\n",
       "        ..., \n",
       "        [   0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ]],\n",
       "\n",
       "       [[  78.56383175,   16.07070067],\n",
       "        [-156.30930098,   82.60566259],\n",
       "        [  -1.17504884,  -11.94092816],\n",
       "        ..., \n",
       "        [  51.09054889,   45.10176147],\n",
       "        [ -42.50160011,   14.63869253],\n",
       "        [ -34.17398567,   42.00768936]],\n",
       "\n",
       "       [[ -82.5500292 ,   74.37502643],\n",
       "        [  75.7058456 ,   79.07511036],\n",
       "        [   9.87229503,    8.8766247 ],\n",
       "        ..., \n",
       "        [  93.92475286,   32.47346174],\n",
       "        [ 125.98491289,    2.88938934],\n",
       "        [ -11.54439463,  -87.79653522]],\n",
       "\n",
       "       ..., \n",
       "       [[  -3.34964591,  -57.15510661],\n",
       "        [ 107.1924515 ,   16.7840736 ],\n",
       "        [ -43.03272037,  -27.82109739],\n",
       "        ..., \n",
       "        [   8.70821454,  -65.18613558],\n",
       "        [ -55.02370508,   36.92777754],\n",
       "        [ -67.0003907 ,   29.83481723]],\n",
       "\n",
       "       [[ -34.61452422,  -31.98703679],\n",
       "        [ -49.88706354,  -87.46444885],\n",
       "        [  30.52609204,   25.6660924 ],\n",
       "        ..., \n",
       "        [  90.29527605,  -14.13141468],\n",
       "        [  62.41506442,  -28.8914289 ],\n",
       "        [ -18.20749075,  -19.33124511]],\n",
       "\n",
       "       [[   0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ],\n",
       "        ..., \n",
       "        [   0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ],\n",
       "        [   0.        ,    0.        ]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35tensorflow",
   "language": "python",
   "name": "py35tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
